{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bdb94260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6a7213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"kaggle_data/items.csv\")\n",
    "interactions = pd.read_csv(\"kaggle_data/interactions_train.csv\")\n",
    "train_df = pd.read_csv(\"kaggle_data/train_data.csv\")\n",
    "test_df = pd.read_csv(\"kaggle_data/test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d818364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users = 7838,\n",
      "Number of items = 15291,\n",
      "Number of interactions = 87047\n"
     ]
    }
   ],
   "source": [
    "n_users = np.max(interactions.u) + 1\n",
    "n_items = np.max(interactions.i) + 1\n",
    "print(f'Number of users = {n_users},\\nNumber of items = {n_items},\\nNumber of interactions = {len(interactions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bd9bbc",
   "metadata": {},
   "source": [
    "# 1. Pure CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae6344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_matrix(data, n_users, n_items):\n",
    "    \"\"\"\n",
    "    This function returns a numpy matrix with shape (n_users, n_items).\n",
    "    Each entry is a binary value indicating positive interaction.\n",
    "    \"\"\"\n",
    "    data_matrix = np.zeros((n_users, n_items))\n",
    "    for row in data.itertuples():\n",
    "        user_id = getattr(row, \"u\")\n",
    "        item_id = getattr(row, \"i\")\n",
    "        rating = getattr(row, \"rating\")\n",
    "        data_matrix[user_id, item_id] = rating\n",
    "    return data_matrix\n",
    "\n",
    "\n",
    "def create_data_matrix_cf(data, n_users, n_items):\n",
    "    \"\"\"\n",
    "    This function returns a numpy matrix with shape (n_users, n_items).\n",
    "    Each entry is a binary value indicating positive interaction.\n",
    "    \"\"\"\n",
    "    data_matrix = np.zeros((n_users, n_items))\n",
    "    for row in data.itertuples():\n",
    "        user_id = getattr(row, \"u\")\n",
    "        item_id = getattr(row, \"i\")\n",
    "        data_matrix[user_id, item_id] = 1\n",
    "    return data_matrix\n",
    "\n",
    "\n",
    "def item_based_predict(interactions, similarity, epsilon=1e-9):\n",
    "    \"\"\"\n",
    "    Predicts user-item interactions based on item-item similarity.\n",
    "    Parameters:\n",
    "        interactions (numpy array): The user-item interaction matrix.\n",
    "        similarity (numpy array): The item-item similarity matrix.\n",
    "        epsilon (float): Small constant added to the denominator to avoid division by zero.\n",
    "    Returns:\n",
    "        numpy array: The predicted interaction scores for each user-item pair.\n",
    "    \"\"\"\n",
    "    pred = similarity.dot(interactions.T) / (\n",
    "        similarity.sum(axis=1)[:, np.newaxis] + epsilon\n",
    "    )\n",
    "    return pred.T\n",
    "\n",
    "\n",
    "def user_based_predict(interactions, similarity, epsilon=1e-9):\n",
    "    \"\"\"\n",
    "    Predicts user-item interactions based on user-user similarity.\n",
    "    Parameters:\n",
    "        interactions (numpy array): The user-item interaction matrix.\n",
    "        similarity (numpy array): The user-user similarity matrix.\n",
    "        epsilon (float): Small constant added to the denominator to avoid division by zero.\n",
    "    Returns:\n",
    "        numpy array: The predicted interaction scores for each user-item pair.\n",
    "    \"\"\"\n",
    "    pred = similarity.dot(interactions) / (\n",
    "        np.abs(similarity).sum(axis=1)[:, np.newaxis] + epsilon\n",
    "    )\n",
    "    return pred\n",
    "\n",
    "\n",
    "def add_rating(df):\n",
    "    interactions = df.copy()\n",
    "    interactions[\"rating\"] = (interactions[\"t\"] - interactions[\"t\"].min()) / (\n",
    "        interactions[\"t\"].max() - interactions[\"t\"].min()\n",
    "    )\n",
    "    interactions_time = interactions.groupby([\"u\", \"i\"], as_index=False).agg(\n",
    "        t_max=(\"rating\", \"max\"), t_count=(\"rating\", \"count\")\n",
    "    )\n",
    "    interactions_time[\"rating\"] = (\n",
    "        np.exp(2 * interactions_time[\"t_max\"]) * interactions_time[\"t_count\"]\n",
    "    )\n",
    "    interactions_time[\"rating\"] = np.log1p(interactions_time[\"rating\"]) * 100\n",
    "    return interactions_time\n",
    "\n",
    "\n",
    "def print_map_10(test_df, prediction, top_k=10):\n",
    "    ground_truth = test_df.groupby(\"u\")[\"i\"].apply(list).to_dict()\n",
    "\n",
    "    user_ids = np.array(range(n_users))\n",
    "    item_ids = np.array(range(n_items))\n",
    "\n",
    "    top10_preds = {}\n",
    "\n",
    "    for idx, user in enumerate(user_ids):\n",
    "        scores = prediction[idx]\n",
    "        top_indices = np.argsort(scores)[::-1][:top_k]\n",
    "        top_items = item_ids[top_indices]\n",
    "        top10_preds[user] = top_items.tolist()\n",
    "\n",
    "    def average_precision_at_k(predicted, actual, k=10):\n",
    "        if not actual:\n",
    "            return 0.0\n",
    "        score = 0.0\n",
    "        num_hits = 0\n",
    "        for i, p in enumerate(predicted[:k]):\n",
    "            if p in actual:\n",
    "                num_hits += 1\n",
    "                score += num_hits / (i + 1)\n",
    "        return score / min(len(actual), k)\n",
    "\n",
    "    ap_scores = [\n",
    "        average_precision_at_k(top10_preds[user], ground_truth[user], k=10)\n",
    "        for user in user_ids\n",
    "        if user in top10_preds\n",
    "    ]\n",
    "\n",
    "    map10 = np.mean(ap_scores)\n",
    "    print(f\"MAP@10: {map10:.4f}\")\n",
    "    return map10\n",
    "\n",
    "\n",
    "def print_map_10_from_csv(test_df: pd.DataFrame, submission_df: pd.DataFrame) -> float:\n",
    "    ground_truth = test_df.groupby(\"u\")[\"i\"].apply(list).to_dict()\n",
    "\n",
    "    predictions = submission_df.set_index(\"user_id\")[\"recommendation\"].apply(\n",
    "        lambda x: list(map(int, x.strip().split()[:10]))\n",
    "    ).to_dict()\n",
    "\n",
    "    def average_precision_at_k(predicted, actual, k=10):\n",
    "        if not actual:\n",
    "            return 0.0\n",
    "        score = 0.0\n",
    "        num_hits = 0\n",
    "        for i, p in enumerate(predicted[:k]):\n",
    "            if p in actual:\n",
    "                num_hits += 1\n",
    "                score += num_hits / (i + 1)\n",
    "        return score / min(len(actual), k)\n",
    "\n",
    "    ap_scores = []\n",
    "    for user, actual_items in ground_truth.items():\n",
    "        if user in predictions:\n",
    "            predicted_items = predictions[user]\n",
    "            ap = average_precision_at_k(predicted_items, actual_items, k=10)\n",
    "            ap_scores.append(ap)\n",
    "\n",
    "    map_10 = np.mean(ap_scores)\n",
    "    print(f\"MAP@10: {map_10:.4f}\")\n",
    "    return map_10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62457a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(prediction, ground_truth, k=10):\n",
    "    \"\"\"\n",
    "    Calculates Precision@K and Recall@K for top-K recommendations.\n",
    "    Parameters:\n",
    "        prediction (numpy array): The predicted interaction matrix with scores.\n",
    "        ground_truth (numpy array): The ground truth interaction matrix (binary).\n",
    "        k (int): Number of top recommendations to consider.\n",
    "    Returns:\n",
    "        precision_at_k (float): The average precision@K over all users.\n",
    "        recall_at_k (float): The average recall@K over all users.\n",
    "    \"\"\"\n",
    "    num_users = prediction.shape[0]\n",
    "    precision_at_k, recall_at_k = 0, 0\n",
    "\n",
    "    for user in range(num_users):\n",
    "        top_k_items = np.argsort(prediction[user, :])[-k:]\n",
    "\n",
    "        relevant_items_in_top_k = np.isin(top_k_items, np.where(ground_truth[user, :] > 0)[0]).sum()\n",
    "\n",
    "        total_relevant_items = ground_truth[user, :].sum()\n",
    "\n",
    "        precision_at_k += relevant_items_in_top_k / k\n",
    "        recall_at_k += relevant_items_in_top_k / total_relevant_items if total_relevant_items > 0 else 0\n",
    "\n",
    "    precision_at_k /= num_users\n",
    "    recall_at_k /= num_users\n",
    "\n",
    "    return precision_at_k, recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01eca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k_from_csv(prediction, ground_truth):\n",
    "    k = 10\n",
    "    num_users = prediction.shape[0]\n",
    "    precision_at_k, recall_at_k = 0, 0\n",
    "\n",
    "    for user in range(num_users):\n",
    "        top_k_items = prediction.loc[prediction.user_id == user, \"recommendation\"].iloc[0].split(' ')\n",
    "        top_k_items = [int(x) for x in top_k_items]\n",
    "\n",
    "        relevant_items_in_top_k = np.isin(top_k_items, np.where(ground_truth[user, :] > 0)[0]).sum()\n",
    "\n",
    "        total_relevant_items = ground_truth[user, :].sum()\n",
    "\n",
    "        precision_at_k += relevant_items_in_top_k / k\n",
    "        recall_at_k += relevant_items_in_top_k / total_relevant_items if total_relevant_items > 0 else 0\n",
    "\n",
    "    precision_at_k /= num_users\n",
    "    recall_at_k /= num_users\n",
    "\n",
    "    return precision_at_k, recall_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56e62b2",
   "metadata": {},
   "source": [
    "## 1.1 User-user CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d9af978",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix_cf = create_data_matrix_cf(train_df, n_users, n_items)\n",
    "user_similarity_cf = cosine_similarity(train_matrix_cf)\n",
    "train_prediction_cf = user_based_predict(train_matrix_cf, user_similarity_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4b63a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = create_data_matrix_cf(test_df, n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "977ba6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.056532278642513596, 0.2906567293761024)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_at_k(train_prediction_cf, test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c252a2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10: 0.1576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15764753477303142"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_map_10(test_df, train_prediction_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a17643",
   "metadata": {},
   "source": [
    "## 1.2 Item-item CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "407f4367",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_similarity_cf = cosine_similarity(train_matrix_cf.T)\n",
    "train_item_prediction = item_based_predict(train_matrix_cf, item_similarity_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2ed0bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05561367695841055, 0.26399361388179715)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_at_k(train_item_prediction, test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0b8748a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10: 0.1443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.14425194703163602"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_map_10(test_df, train_item_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a26c29e",
   "metadata": {},
   "source": [
    "# 2. CF with rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f87ea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_rating = add_rating(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3812ae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = create_data_matrix(train_df_rating, n_users, n_items)\n",
    "user_similarity = cosine_similarity(train_matrix)\n",
    "train_prediction = user_based_predict(train_matrix, user_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b108facc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0611635621332006, 0.2954780242458611)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_at_k(train_prediction, test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b63e710a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10: 0.1673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16725996993332032"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_map_10(test_df, train_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8631de3c",
   "metadata": {},
   "source": [
    "# 3. Puring embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1316cdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_df(file_name):\n",
    "    results_df = pd.DataFrame(columns=[\"i\", \"custom_id\", \"vector\"])\n",
    "    with open(file_name, \"r\") as file:\n",
    "        for line in tqdm(file):\n",
    "            # Parsing the JSON string into a dict and appending to the list of results\n",
    "            json_object = json.loads(line.strip())\n",
    "            custom_id = json_object[\"custom_id\"]\n",
    "            i = custom_id.split(\"-\")[1]\n",
    "            vector = json_object[\"response\"][\"body\"][\"data\"][0][\"embedding\"]\n",
    "            vector = np.array(vector)\n",
    "            # Add the new row to the DataFrame\n",
    "            results_df = pd.concat(\n",
    "                [\n",
    "                    results_df,\n",
    "                    pd.DataFrame(\n",
    "                        {\"i\": [i], \"custom_id\": [custom_id], \"vector\": [vector]}\n",
    "                    ),\n",
    "                ],\n",
    "                ignore_index=True,\n",
    "            )\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f76017a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15291it [00:06, 2341.32it/s]\n",
      "15291it [00:06, 2274.68it/s]\n",
      "15291it [00:06, 2290.09it/s]\n",
      "15291it [00:06, 2315.12it/s]\n",
      "15291it [00:06, 2334.95it/s]\n",
      "15291it [00:06, 2291.47it/s]\n"
     ]
    }
   ],
   "source": [
    "semantic_tags = create_embedding_df(\"./items_embedding/emb_semantic_tags_output.jsonl\")\n",
    "subgenre = create_embedding_df(\"./items_embedding/emb_subgenre_output.jsonl\")\n",
    "summary = create_embedding_df(\"./items_embedding/emb_summary_output.jsonl\")\n",
    "target_audience = create_embedding_df(\"./items_embedding/emb_target_audience_output.jsonl\")\n",
    "themes = create_embedding_df(\"./items_embedding/emb_themes_output.jsonl\")\n",
    "tone_mood = create_embedding_df(\"./items_embedding/emb_tone_mood_output.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ed99cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_index(df):\n",
    "    if (df.index == df.i.astype(int)).all():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48474af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(semantic_tags) == len(subgenre) == len(summary) == len(target_audience) == len(themes) == len(tone_mood) == len(items), \"DataFrames have different lengths\"\n",
    "assert check_index(semantic_tags), \"Index of semantic_tags is not correct\"\n",
    "assert check_index(subgenre), \"Index of subgenre is not correct\"\n",
    "assert check_index(summary), \"Index of summary is not correct\"\n",
    "assert check_index(target_audience), \"Index of target_audience is not correct\"\n",
    "assert check_index(themes), \"Index of themes is not correct\"\n",
    "assert check_index(tone_mood), \"Index of tone_mood is not correct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0eda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_similarity_matrix(vector_df):\n",
    "    book_matrix = np.vstack(vector_df.vector.to_list())\n",
    "    book_similarity = cosine_similarity(book_matrix)\n",
    "    return book_similarity\n",
    "\n",
    "\n",
    "def fast_recommend_to_df(interactions_df, similarity_matrix, top_n=10):\n",
    "    user_ids = interactions_df['u'].unique()\n",
    "    num_users = len(user_ids)\n",
    "    num_items = similarity_matrix.shape[0]\n",
    "\n",
    "    user_id_to_index = {uid: idx for idx, uid in enumerate(user_ids)}\n",
    "    index_to_user_id = {idx: uid for uid, idx in user_id_to_index.items()}\n",
    "\n",
    "    interactions_df = interactions_df.sort_values([\"u\", \"t_max\"]).reset_index(drop=True)\n",
    "    interactions_df[\"pct_rank\"] = interactions_df.groupby(\"u\")[\"t_max\"].rank(pct=True, method='dense')\n",
    "\n",
    "    interaction_matrix = np.zeros((num_users, num_items))\n",
    "    for _, row in interactions_df.iterrows():\n",
    "        u_idx = user_id_to_index[row['u']]\n",
    "        i_idx = int(row['i'])\n",
    "        if row['pct_rank'] < 0.7:\n",
    "            interaction_matrix[u_idx, i_idx] = 0\n",
    "        else:\n",
    "            interaction_matrix[u_idx, i_idx] = np.exp(2 * row[\"t_max\"])\n",
    "\n",
    "    score_matrix = interaction_matrix @ similarity_matrix\n",
    "\n",
    "    records = []\n",
    "    for u_idx in range(num_users):\n",
    "        top_items = np.argpartition(score_matrix[u_idx], -top_n)[-top_n:]\n",
    "        top_items_sorted = top_items[np.argsort(score_matrix[u_idx][top_items])[::-1]]\n",
    "        records.append({\n",
    "            \"user_id\": index_to_user_id[u_idx],\n",
    "            \"recommendation\": \" \".join([str(x) for x in top_items_sorted])\n",
    "        })\n",
    "\n",
    "    recommendations_df = pd.DataFrame(records)\n",
    "    return recommendations_df, score_matrix\n",
    "\n",
    "\n",
    "def row_min_max_normalize(score_matrix):\n",
    "    min_vals = np.min(score_matrix, axis=1, keepdims=True)\n",
    "    max_vals = np.max(score_matrix, axis=1, keepdims=True)\n",
    "\n",
    "    denom = np.where(max_vals - min_vals == 0, 1, max_vals - min_vals)\n",
    "    normalized = (score_matrix - min_vals) / denom\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e7ced6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_book_similarity = get_book_similarity_matrix(semantic_tags)\n",
    "tone_book_similarity = get_book_similarity_matrix(tone_mood)\n",
    "subgenre_book_similarity = get_book_similarity_matrix(subgenre)\n",
    "summary_book_similarity = get_book_similarity_matrix(summary)\n",
    "target_audience_book_similarity = get_book_similarity_matrix(target_audience)\n",
    "themes_book_similarity = get_book_similarity_matrix(themes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "581f2324",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_recommend_df, semantic_score_matrix = fast_recommend_to_df(train_df_rating, semantic_book_similarity)\n",
    "tone_recommend_df, tone_score_matrix = fast_recommend_to_df(train_df_rating, tone_book_similarity)\n",
    "subgenre_recommend_df, subgenre_score_matrix = fast_recommend_to_df(train_df_rating, subgenre_book_similarity)\n",
    "summary_recommend_df, summary_score_matrix = fast_recommend_to_df(train_df_rating, summary_book_similarity)\n",
    "target_audience_recommend_df, target_audience_score_matrix = fast_recommend_to_df(train_df_rating, target_audience_book_similarity)\n",
    "themes_recommend_df, themes_score_matrix = fast_recommend_to_df(train_df_rating, themes_book_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecb27400",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cf_normalized = row_min_max_normalize(train_prediction)\n",
    "score_semantic_normalized = row_min_max_normalize(semantic_score_matrix)\n",
    "score_tone_normalized = row_min_max_normalize(tone_score_matrix)\n",
    "score_subgenre_normalized = row_min_max_normalize(subgenre_score_matrix)\n",
    "score_summary_normalized = row_min_max_normalize(summary_score_matrix)\n",
    "score_target_audience_normalized = row_min_max_normalize(target_audience_score_matrix)\n",
    "score_themes_normalized = row_min_max_normalize(themes_score_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48e9abae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03914263842817062, 0.2289522321277847)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_at_k(semantic_score_matrix, test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbd8b555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10: 0.1320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1319927161122262"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_map_10(test_df, semantic_score_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041e61d",
   "metadata": {},
   "source": [
    "# 4. Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e7d84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_hybrid = 0.92 * np.log1p(score_cf_normalized) + \\\n",
    "      0.2 * score_semantic_normalized + \\\n",
    "      0.0 * score_tone_normalized + \\\n",
    "      0.0 * np.log1p(score_subgenre_normalized) + \\\n",
    "      0.8 * np.log1p(score_summary_normalized) + \\\n",
    "      0.0 * np.log1p(score_target_audience_normalized) + \\\n",
    "      0.01 * np.log1p(score_themes_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "135f0cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06358764991069532, 0.31800260329478647)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_at_k(score_hybrid, test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11290021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10: 0.1772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17716294016330694"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_map_10(test_df, score_hybrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124289a6",
   "metadata": {},
   "source": [
    "# 5. Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9da0ccf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "MAX_INPUT_LEN = 10\n",
    "PREDICT_LEN = 5\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1000\n",
    "EMB_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "VOCAB_SIZE = 15298"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e92f257",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerPredictor(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, emb_dim, hidden_dim, output_len, max_len=MAX_INPUT_LEN\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, max_len, emb_dim))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=emb_dim, nhead=4, dim_feedforward=hidden_dim\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=2)\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(emb_dim, output_len), nn.ReLU()  # 保证 offset ≥ 0\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pad_mask = x == 0\n",
    "        seq_len = x.size(1)\n",
    "        emb = self.embedding(x) + self.positional_encoding[:, :seq_len, :]\n",
    "        emb = emb.permute(1, 0, 2)\n",
    "        encoded = self.encoder(emb, src_key_padding_mask=pad_mask)\n",
    "        pooled = encoded[-1]\n",
    "        return self.output_layer(pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dac92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"transformer_checkpoint.pt\", map_location=device)\n",
    "model = TransformerPredictor(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    emb_dim=EMB_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_len=PREDICT_LEN\n",
    ")\n",
    "model.load_state_dict(checkpoint)\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40f48fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "u",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "i",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "e60202d0-4959-40c6-9575-a9e3ef28100a",
       "rows": [
        [
         "0",
         "[9, 10, 11, 13, 12, 14, 15, 16, 17, 18]"
        ],
        [
         "1",
         "[31, 32, 33, 34, 35, 36, 36, 36, 37, 37]"
        ],
        [
         "2",
         "[81, 81, 81, 81, 83, 84, 81, 81, 85, 86]"
        ],
        [
         "3",
         "[150, 151, 152, 153, 154, 155, 156, 157, 158, 159]"
        ],
        [
         "4",
         "[195, 196, 197, 198, 199, 200, 201, 202, 203, 204]"
        ],
        [
         "5",
         "[212, 213, 214, 215, 216, 217, 218, 219, 220, 221]"
        ],
        [
         "6",
         "[229, 230, 231, 229, 229, 230]"
        ],
        [
         "7",
         "[237, 238, 239, 240, 241, 242, 243, 244, 245, 246]"
        ],
        [
         "8",
         "[256, 257]"
        ],
        [
         "9",
         "[262, 262, 263, 264, 264, 264, 264, 262, 262, 261]"
        ],
        [
         "10",
         "[268, 269, 270, 271, 272]"
        ],
        [
         "11",
         "[277, 278, 279]"
        ],
        [
         "12",
         "[284, 285, 286, 287, 288, 285, 289, 290, 291, 292]"
        ],
        [
         "13",
         "[311, 321, 313, 328, 329, 330, 319, 331, 332, 333]"
        ],
        [
         "14",
         "[340, 341, 342, 343, 344, 345, 346, 317, 347, 348]"
        ],
        [
         "15",
         "[354, 355]"
        ],
        [
         "16",
         "[359, 360]"
        ],
        [
         "17",
         "[363, 364]"
        ],
        [
         "18",
         "[367, 367, 367, 367, 368, 368]"
        ],
        [
         "19",
         "[371, 378, 379, 380, 381, 380, 377, 382, 377, 383]"
        ],
        [
         "20",
         "[397, 396, 395, 394, 399, 401, 400, 398, 397, 396]"
        ],
        [
         "21",
         "[403, 404, 405]"
        ],
        [
         "22",
         "[409, 410, 296]"
        ],
        [
         "23",
         "[474, 475, 476, 477, 478, 479, 480, 481, 482, 483]"
        ],
        [
         "24",
         "[535, 530, 535, 537, 536, 525, 526, 538, 529, 533]"
        ],
        [
         "25",
         "[540, 541, 542, 543, 544, 545, 546, 545, 543, 51]"
        ],
        [
         "26",
         "[552, 553, 554, 555, 556]"
        ],
        [
         "27",
         "[571, 562, 566, 565, 564, 562, 571, 572, 565, 564]"
        ],
        [
         "28",
         "[577, 578, 577, 579, 580, 581, 578]"
        ],
        [
         "29",
         "[588, 589, 590, 591, 592, 593, 83, 594, 595, 596]"
        ],
        [
         "30",
         "[610, 621, 622, 623, 623, 623, 623, 608, 608, 624]"
        ],
        [
         "31",
         "[169, 634]"
        ],
        [
         "32",
         "[636, 637, 638, 638, 639, 640, 641, 638, 642, 642]"
        ],
        [
         "33",
         "[648, 649]"
        ],
        [
         "34",
         "[653, 654, 466, 655, 656, 657, 658, 659]"
        ],
        [
         "35",
         "[665, 666]"
        ],
        [
         "36",
         "[669, 669, 669]"
        ],
        [
         "37",
         "[670, 671]"
        ],
        [
         "38",
         "[692, 693, 692, 694, 695, 696, 697, 698, 699, 700]"
        ],
        [
         "39",
         "[718, 719, 720, 721, 720, 718, 719, 721, 719]"
        ],
        [
         "40",
         "[724, 725, 726, 584, 727, 728, 729, 730, 730, 730]"
        ],
        [
         "41",
         "[809, 810, 778, 811, 812, 813, 814, 815, 488, 464]"
        ],
        [
         "42",
         "[874, 875, 876, 877, 878, 879, 880, 881, 876, 882]"
        ],
        [
         "43",
         "[899, 899, 898, 897, 898, 898, 897, 897, 897, 898]"
        ],
        [
         "44",
         "[900, 901, 902, 903, 904]"
        ],
        [
         "45",
         "[962, 963, 939, 964, 965, 966, 967, 968, 969, 970]"
        ],
        [
         "46",
         "[1001, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012]"
        ],
        [
         "47",
         "[1069, 1037, 1070, 1071, 1072, 970, 1073, 1074, 1075, 1076]"
        ],
        [
         "48",
         "[1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113]"
        ],
        [
         "49",
         "[1119, 1120, 1121, 1122, 1123]"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 7838
       }
      },
      "text/plain": [
       "u\n",
       "0                 [9, 10, 11, 13, 12, 14, 15, 16, 17, 18]\n",
       "1                [31, 32, 33, 34, 35, 36, 36, 36, 37, 37]\n",
       "2                [81, 81, 81, 81, 83, 84, 81, 81, 85, 86]\n",
       "3       [150, 151, 152, 153, 154, 155, 156, 157, 158, ...\n",
       "4       [195, 196, 197, 198, 199, 200, 201, 202, 203, ...\n",
       "                              ...                        \n",
       "7833                                          [975, 7322]\n",
       "7834               [15276, 13891, 7128, 7128, 7128, 7128]\n",
       "7835                                         [4820, 3055]\n",
       "7836                                        [14550, 3471]\n",
       "7837                                           [2191, 88]\n",
       "Name: i, Length: 7838, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_history = train_df.groupby('u')['i'].apply(list).apply(lambda x: x[-10:] if len(x) >= 10 else x)\n",
    "train_user_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a826147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(history):\n",
    "    history_tensor = torch.tensor([history], dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        offset_pred = model(history_tensor)\n",
    "        base = history_tensor[0, -1]\n",
    "        pred_item_ids = (offset_pred + base).round()\n",
    "    return [int(x) for x in pred_item_ids.cpu().tolist()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01ee0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = pd.DataFrame(columns=[\"user_id\", \"recommendation\"])\n",
    "results_train[\"user_id\"] = np.arange(n_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c68cbe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7838it [00:08, 977.62it/s] \n"
     ]
    }
   ],
   "source": [
    "for idx, row in tqdm(results_train.iterrows()):\n",
    "    current_user = row[\"user_id\"]\n",
    "    if current_user < 1200:\n",
    "        pred = get_pred(train_user_history.iloc[current_user])[:3]\n",
    "        from_scores = np.argsort(score_hybrid[current_user, :])[-7:][::-1].tolist()\n",
    "        final = pred + from_scores\n",
    "    else:\n",
    "        final = np.argsort(score_hybrid[current_user, :])[-10:][::-1].tolist()\n",
    "    results_train.at[idx, \"recommendation\"] = \" \".join(str(x) for x in final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ac6aadef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.07036233733095643, 0.34686592860705867)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_at_k_from_csv(results_train, test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b2022eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@10: 0.1958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.19580166326025936"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_map_10_from_csv(test_df, results_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e225402",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
